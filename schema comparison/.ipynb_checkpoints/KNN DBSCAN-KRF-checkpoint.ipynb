{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from numpy import sqrt, square\n",
    "from kneed import KneeLocator\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Training Data\n",
    "path =r\"E:\\PROJECT\\VSCode Python Project\\Sensor Network\\Uji Coba\\Progress Skripsi\\Data\\Data Nico\\Data 15 April Tanpa Gangguan\\Train 1\"\n",
    "globbed_files = glob.glob(path + \"/*.csv\")\n",
    "data = []\n",
    "for csv in globbed_files:\n",
    "    frame = pd.read_csv(csv)\n",
    "    frame['x'] = os.path.basename(csv).split('.')[0][0]\n",
    "    frame['y'] = os.path.basename(csv).split('.')[0][1]\n",
    "    data.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load Training Data 2\n",
    "# path2 =r\"E:\\PROJECT\\VSCode Python Project\\Sensor Network\\Uji Coba\\Progress Skripsi\\Data\\Data Nico\\Data 15 April Tanpa Gangguan\\Train 1\"\n",
    "# globbed_files2 = glob.glob(path2 + \"/*.csv\")\n",
    "# for csv in globbed_files2:\n",
    "#     frame = pd.read_csv(csv)\n",
    "#     frame['x'] = os.path.basename(csv).split('.')[0][0]\n",
    "#     frame['y'] = os.path.basename(csv).split('.')[0][1]\n",
    "#     data.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take the lowest number of set data (32)\n",
    "attempt = []\n",
    "for i, item in enumerate(data):\n",
    "    attempt.append(data[i][['Router 1','Router 2','Router 3','Router 4','x','y']]) #.head(32)\n",
    "attempt_concat = pd.concat(attempt)\n",
    "data_train = attempt_concat.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_train[['Router 1','Router 2','Router 3','Router 4']] = data_train[['Router 1','Router 2','Router 3','Router 4']].abs()\n",
    "data_train = data_train.assign(Unique_ID = (data_train['x'].astype(str) + '_' + data_train['y'].astype(str)).astype('category').cat.codes)\n",
    "x_train = data_train.iloc[:,0:4].values\n",
    "y_train = data_train.iloc[:,4:]\n",
    "ref_table = y_train.iloc[:, [0,1,2]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_left =r\"E:\\PROJECT\\VSCode Python Project\\Sensor Network\\Uji Coba\\Progress Skripsi\\Data\\Data Nico\\Data 15 April Tanpa Gangguan\\Test\\Left Test\"\n",
    "globbed_files_left = glob.glob(path_left + \"/*.csv\")\n",
    "data_left = []\n",
    "for csv in globbed_files_left:\n",
    "    frame = pd.read_csv(csv)\n",
    "    frame['x'] = os.path.basename(csv).split('.')[0][0]\n",
    "    frame['y'] = os.path.basename(csv).split('.')[0][1]\n",
    "    data_left.append(frame)\n",
    "    \n",
    "attempt_left = []\n",
    "for i, item in enumerate(data_left):\n",
    "    attempt_left.append(data_left[i][['Router 1','Router 2','Router 3','Router 4','x','y']])\n",
    "attempt_concat_left = pd.concat(attempt_left)\n",
    "data_test_left = attempt_concat_left.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_test_left[['Router 1','Router 2','Router 3','Router 4']] = data_test_left[['Router 1','Router 2','Router 3','Router 4']] .abs()\n",
    "data_test_left = data_test_left.tail(562).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split features and label\n",
    "x_test_left = data_test_left.iloc[:,0:4].values\n",
    "y_test_left = data_test_left.iloc[:,4:]\n",
    "\n",
    "### Normalization\n",
    "# x_test_left = scaler.transform(x_test_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _PCA():\n",
    "    def __init__(self, dataset, perc_of_var):\n",
    "        '''\n",
    "        param perc_of_var : (float) percent of variance from PCA\n",
    "        return None\n",
    "        '''\n",
    "        self.data = dataset\n",
    "        self.perc_of_var = perc_of_var\n",
    "\n",
    "    def _train(self):\n",
    "        '''\n",
    "        param x_train : (DataFrame) Training Dataset\n",
    "        return x_train : (DataFrame) Training Dataset after PCA\n",
    "        return dim_red : param fitter for test data\n",
    "        '''\n",
    "        dim_red = PCA(n_components = self.perc_of_var, svd_solver='full')\n",
    "        x_train = dim_red.fit_transform(self.data)\n",
    "        return x_train, dim_red\n",
    "\n",
    "    def _test(self, test, dim_red):\n",
    "        '''\n",
    "        Preforms PCA and keeps perc_of_var percent of variance \n",
    "        param x_test : (DataFrame) Test Dataset\n",
    "        param dim_red : (pca) Instance of PCA\n",
    "        return x_test : (DataFrame) Test Dataset after PCA\n",
    "        '''\n",
    "        x_test = dim_red.transform(test)\n",
    "        return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = _PCA(x_train, 0.95)\n",
    "# x_train, dim_red = pca._train()\n",
    "# x_test_left = pca._test(x_test_left,dim_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform DBSCAN Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbors = NearestNeighbors(n_neighbors=5)\n",
    "neighbors = nearest_neighbors.fit(x_train)\n",
    "distances, indices = neighbors.kneighbors(x_train)\n",
    "distances = np.sort(distances[:,4], axis=0)\n",
    "i = np.arange(len(distances))\n",
    "knee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=distances[knee.knee], min_samples=6).fit(x_train)\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "       16, 17, 18, 19, 20, 21, 22, 23], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 0\n"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0) # jumlah cluster, total klas - 1 (kalo ada noise)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train,columns=['PC_1','PC_2','PC_3','PC_4'])\n",
    "y_train['dbscan_1'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat((x_train_df,y_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_core = combined.loc[~(combined['dbscan_1'] == -1)]\n",
    "combined_core = combined_core.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cr = combined_core.iloc[:,0:4]\n",
    "y_train_cr = combined_core.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform DBSCAN Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PC_1  PC_2  PC_3  PC_4\n",
       "0     66    68    32    66\n",
       "1     48    68    62    66\n",
       "2     61    35    61    67\n",
       "3     66    61    52    58\n",
       "4     66    56    75    32\n",
       "..   ...   ...   ...   ...\n",
       "91    66    56    75    32\n",
       "92    66    68    33    66\n",
       "93    66    68    32    66\n",
       "94    67    62    62    62\n",
       "95    66    61    52    58\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\kneed\\knee_locator.py:218: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - min(a)) / (max(a) - min(a))\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:77: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  results &= comparator(main, plus)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:78: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  results &= comparator(main, minus)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:77: RuntimeWarning: invalid value encountered in less_equal\n",
      "  results &= comparator(main, plus)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\scipy\\signal\\_peak_finding.py:78: RuntimeWarning: invalid value encountered in less_equal\n",
      "  results &= comparator(main, minus)\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\kneed\\knee_locator.py:242: RuntimeWarning: No local maxima found in the difference curve\n",
      "The line is probably not polynomial, try plotting\n",
      "the difference curve with plt.plot(knee.x_difference, knee.y_difference)\n",
      "Also check that you aren't mistakenly setting the curve argument\n",
      "  RuntimeWarning,\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors_cr = NearestNeighbors(n_neighbors=5)\n",
    "neighbors_cr = nearest_neighbors_cr.fit(x_train_cr)\n",
    "distances_cr, indices_cr = neighbors_cr.kneighbors(x_train_cr)\n",
    "distances_cr = np.sort(distances_cr[:,4], axis=0)\n",
    "i_cr = np.arange(len(distances_cr))\n",
    "knee_cr = KneeLocator(i_cr, distances_cr, S=1, curve='convex', direction='increasing', interp_method='polynomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1b22acfbd9fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb_cr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistances_cr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mknee_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknee\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_cr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels_cr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\NicolasEnv\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"eps must be positive.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "db_cr = DBSCAN(eps=distances_cr[knee_cr.knee], min_samples=5).fit(x_train_cr)\n",
    "labels_cr = db_cr.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cr_df = pd.DataFrame(x_train_cr,columns=['PC_1','PC_2','PC_3','PC_4'])\n",
    "y_train_cr['dbscan_2'] = labels_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cr = pd.concat((x_train_cr_df,y_train_cr),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cr_2 = combined_cr.loc[~(combined_cr['dbscan_2'] == -1)]\n",
    "combined_cr_2 = combined_cr_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cr_2 = combined_cr_2.iloc[:,0:4]\n",
    "y_train_cr_2 = combined_cr_2.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalaced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {}\n",
    "clusters = {}\n",
    "for x in np.unique(combined_cr_2.values[:,-1]):\n",
    "    dict_[x] = list(combined_cr_2[combined_cr_2.dbscan_2 == x]['Unique_ID'].values)\n",
    "    clusters[x] = list(combined_cr_2[combined_cr_2.dbscan_2 == x][['PC_1', 'PC_2', 'PC_3', 'PC_4']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_dict(y):\n",
    "    '''\n",
    "    balancing for oversampling strategy\n",
    "    '''\n",
    "    new_strategy = {}\n",
    "    keys = Counter(y).keys()\n",
    "    values = max(Counter(y).values())\n",
    "    for key in keys:\n",
    "        new_strategy[key] = values\n",
    "    return new_strategy\n",
    "\n",
    "## untuk bantu train regressor\n",
    "def over_sampling(clusters, dict_, index):\n",
    "    '''\n",
    "    random oversampling strategy\n",
    "    '''\n",
    "    x_total = {}\n",
    "    y_total = {}\n",
    "    for i,item in enumerate(index):\n",
    "        if len(item) > 1:\n",
    "            x = [z for z in clusters[list(clusters.keys())[i]]]\n",
    "            y = [z for z in dict_[list(dict_.keys())[i]]]\n",
    "            strategy = strategy_dict(y)\n",
    "            oversample = RandomOverSampler(sampling_strategy=strategy)\n",
    "            x_over, y_over = oversample.fit_resample(x, y)\n",
    "            x_total[list(clusters.keys())[i]] = np.array(x_over)\n",
    "            y_total[list(clusters.keys())[i]] = np.array(y_over)\n",
    "        else:\n",
    "            x_total[list(clusters.keys())[i]] = np.array([z for z in clusters[list(clusters.keys())[i]]])\n",
    "            y_total[list(clusters.keys())[i]] = np.array([z for z in dict_[list(dict_.keys())[i]]])\n",
    "    return x_total, y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = [list(np.unique(x)) for x in dict_.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total, y_total = over_sampling(clusters, dict_, unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Sensitive and Insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_insensitive = {}\n",
    "y_insensitive = {}\n",
    "for x in [i for i, x in enumerate(unique) if len(x) > 1]:\n",
    "    x_insensitive[x] = x_total[x]\n",
    "    y_insensitive[x] = y_total[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matching process between new id and ref table\n",
    "data_balanced = {}\n",
    "for i, (x,y) in enumerate(zip(x_insensitive, y_insensitive)):\n",
    "    data_balanced[\"{0}\".format(list(x_insensitive.keys())[i])] = y_insensitive[y]\n",
    "data_df_balanced = pd.DataFrame.from_dict(data_balanced, orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list_id(df_id, ref_table):\n",
    "    dict_loc = {}; id_total = []\n",
    "    m_total = ref_table.shape[0]\n",
    "    poses = []\n",
    "    for c in df_id:\n",
    "        x = []\n",
    "        for i in range(len(df_id[c].dropna())):\n",
    "            x.append(int(df_id[c][i]))\n",
    "        var = np.array(x)\n",
    "        id_total.append(var)\n",
    "    for i in range(m_total):\n",
    "        key = int(ref_table.iloc[i]['Unique_ID'])\n",
    "        value = ref_table.iloc[i, 0:2].values\n",
    "        dict_loc[key] = value\n",
    "    for i in range(len(id_total)):\n",
    "        pos = []\n",
    "        for j in range(len(id_total[i])):\n",
    "            x = id_total[i][j]\n",
    "            pos.append(dict_loc.get(x))\n",
    "        pos = np.array(pos)\n",
    "        poses.append(pos)    \n",
    "    return id_total, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_total_balanced, poses_balanced = filter_list_id(data_df_balanced, ref_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(id_total,poses,i):\n",
    "    df_id = pd.DataFrame(id_total[i],columns=[str(i)])\n",
    "    df_pos = pd.DataFrame(poses[i],columns=['x','y'])\n",
    "    return df_pos, df_id\n",
    "\n",
    "df = {}\n",
    "for i, (_id,pose) in enumerate(zip(id_total_balanced,poses_balanced)):\n",
    "    df[list(x_insensitive.keys())[i]] = pd.concat((make_df(id_total_balanced,poses_balanced,i)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained and Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression model for pose prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def tuning_regr_rf(x_train,y_train):\n",
    "    QUANTITATIVE_COLUMNS = ['x', 'y']\n",
    "    regr = RandomForestRegressor()\n",
    "    \n",
    "    n_estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    hyperparameters = {'n_estimators':n_estimators}\n",
    "     \n",
    "    grid = GridSearchCV(estimator = regr,\n",
    "                        param_grid = hyperparameters,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        cv = 3,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "    tic = time.time()\n",
    "    grid_result_regr = grid.fit(x_train,y_train[QUANTITATIVE_COLUMNS].values.astype(np.float64))\n",
    "    toc = time.time()\n",
    "    run_time = (toc - tic)/60\n",
    "    return grid_result_regr.best_estimator_, grid_result_regr.best_score_, run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression model for pose prediction\n",
    "def tuning_regr_knn(x_train,y_train):\n",
    "    QUANTITATIVE_COLUMNS = ['x', 'y']\n",
    "    regr = KNeighborsRegressor(n_neighbors=1)\n",
    "    \n",
    "    metric = ['manhattan','minkowski','euclidean']\n",
    "    hyperparameters = {'metric': metric}\n",
    "     \n",
    "    grid = GridSearchCV(estimator = regr,\n",
    "                        param_grid = hyperparameters,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        cv = 3,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "    tic = time.time()\n",
    "    grid_result_regr = grid.fit(x_train,y_train[QUANTITATIVE_COLUMNS].values.astype(np.float64))\n",
    "    toc = time.time()\n",
    "    run_time = (toc - tic)/60\n",
    "    return grid_result_regr.best_estimator_, grid_result_regr.best_score_, run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr_tuned = {}\n",
    "# for i,(x,y) in enumerate(zip(x_total,df)):\n",
    "#     regr, regr_score, runtime_regr = tuning_regr_knn(x_total[x], df[y])\n",
    "#     regr_tuned[\"regr_{0}\".format(list(x_total.keys())[i])] = regr, regr_score, runtime_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_tuned = {}\n",
    "for i,(x,y) in enumerate(zip(x_insensitive,df)):\n",
    "    regr, regr_score, runtime_regr = tuning_regr_rf(x_insensitive[x], df[y])\n",
    "    regr_tuned[\"regr_{0}\".format(list(x_insensitive.keys())[i])] = regr, regr_score, runtime_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_left['Unique_ID'] = [int(ref_table[(ref_table.x == str(x[0])) & (ref_table.y == str(x[1]))]['Unique_ID'].values) \n",
    "                              for x in y_test_left.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def nn_modified(test_noises, x_train, y_train):\n",
    "    distance_n = []\n",
    "    for x,y in zip(x_train, y_train):\n",
    "        dim = np.array(x).shape[0]\n",
    "        eu_distance = sp.spatial.distance.euclidean(test_noises.reshape(1,dim),np.array(x).reshape(1,dim))\n",
    "        distance_n.append((eu_distance,y))\n",
    "    distance_n = sorted(distance_n)[0][1]\n",
    "    return distance_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_ = []\n",
    "for n in x_test_left:\n",
    "    clus_.append(nn_modified(n, x_train_cr_2.values, y_train_cr_2['dbscan_2'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(x_test_left, clus_, dict_, x_insensitive, regr_tuned, ref_table):\n",
    "    result = []\n",
    "    for i, (x,y) in enumerate(zip(x_test_left, clus_)):\n",
    "        if y in list(x_insensitive.keys()):\n",
    "            data = x.reshape(1,len(x))\n",
    "            result.append(regr_tuned['regr_{0}'.format(int(y))][0].predict(data).astype(int).reshape(2,))\n",
    "        else:\n",
    "            y_ = np.unique(dict_[y])\n",
    "            result.append(ref_table[ref_table.Unique_ID == int(y_)][['x','y']].values.astype(int).reshape(2,))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_prediction(x_test_left, clus_, dict_, x_insensitive, regr_tuned, ref_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(result,columns=['x_pred','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_core, index_noises = index_nc(clus_)\n",
    "\n",
    "# test_core = x_test_left[index_core] ## core point testing\n",
    "# test_noises = x_test_left[index_noises]\n",
    "\n",
    "# label_core = y_test_left.values[index_core] ## core point testing\n",
    "# label_noises = y_test_left.values[index_noises]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_core = np.append(test_core, np.array(clus_knn)[index_core].reshape(len(np.array(clus_knn)[index_core]),1).astype(int), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class POS_Regr(): \n",
    "#     '''\n",
    "#     Generate object for Coordinate Result\n",
    "#     '''\n",
    "#     def getRegr(self):\n",
    "#         return self.regr\n",
    "#     def __init__(self, regr):\n",
    "#         self.regr = regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_prediction(prep_core, regr_tuned):\n",
    "#     buff = []\n",
    "#     for i,item in enumerate(prep_core):\n",
    "#         N = len(item)-1\n",
    "#         data = item[0:N].reshape(1,N)\n",
    "#         hasil = regr_tuned['regr_{0}'.format(item[-1].astype(int))][0].predict(data)\n",
    "#         value = POS_Regr(hasil)\n",
    "#         buff.append(value)\n",
    "#     return buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = test_prediction(prep_core, regr_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_prediction(pred):\n",
    "#     df_prediction = []\n",
    "#     for i in range(len(pred)):\n",
    "#         xs = list(pred[i].getRegr()[0])\n",
    "#         df_prediction.append(xs)\n",
    "#     dataset = pd.DataFrame(df_prediction,columns=['x_pred','y_pred']) \n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred = df_prediction(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_n ## data latih untuk noises\n",
    "# y_train_n ## label latih untuk noises\n",
    "# test_noises ## data test untuk noises\n",
    "# label_noises ## label test untuk noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Balancing data for noises\n",
    "# dict_n_ = {}\n",
    "# clusters_n = {}\n",
    "# for x in np.unique(combined_noise.values[:,-1]):\n",
    "#     dict_n_[x] = list(combined_noise['Unique_ID'].values)\n",
    "#     clusters_n[x] = list(combined_noise[['PC_1', 'PC_2', 'PC_3', 'PC_4']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_n = [list(np.unique(x)) for x in dict_n_.values()]\n",
    "# x_total_n, y_total_n = over_sampling(clusters_n, dict_n_, unique_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## matching process between new id and ref table\n",
    "# data_balanced_n = {}\n",
    "# data_balanced_n[\"-1\"] = y_total_n[-1]\n",
    "# data_df_balanced_n = pd.DataFrame.from_dict(data_balanced_n, orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_total_balanced_n, poses_balanced_n = filter_list_id(data_df_balanced_n, ref_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_n = {}\n",
    "# df_n[-1] = pd.concat((make_df(id_total_balanced_n,poses_balanced_n,0)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr_n, regr_score_n, runtime_regr_n = tuning_regr_rf(x_total_n[-1], df_n[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### testing model for unseen data\n",
    "# pred_n = regr_n.predict(test_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_n = pd.DataFrame(pred_n,columns=['x_pred','y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Regression Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regr_error(df_final,label_core):\n",
    "    x, y  = df_final['x_pred'].values, df_final['y_pred'].values\n",
    "    x0, y0 = label_core[:,0].astype(int), label_core[:,1].astype(int)\n",
    "    coords_error = np.sqrt(np.square(x - x0) + np.square(y - y0))\n",
    "    mean_loc_error = coords_error.mean()\n",
    "    return mean_loc_error, coords_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## core point error\n",
    "mean_loc_error, coords_error = calculate_regr_error(df_pred,y_test_left.values)\n",
    "print(mean_loc_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## noises point error\n",
    "# mean_loc_error_n, coords_error_n = calculate_regr_error(dataset_n,label_noises)\n",
    "# print(mean_loc_error_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# ### Error gabungan\n",
    "# np.sum((len(label_core) * mean_loc_error)+(len(label_noises) * mean_loc_error_n)) / (len(label_core) + len(label_noises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NicolasEnv] *",
   "language": "python",
   "name": "conda-env-NicolasEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
